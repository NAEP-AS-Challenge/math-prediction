<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>book</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="book_files/libs/clipboard/clipboard.min.js"></script>
<script src="book_files/libs/quarto-html/quarto.js"></script>
<script src="book_files/libs/quarto-html/popper.min.js"></script>
<script src="book_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="book_files/libs/quarto-html/anchor.min.js"></script>
<link href="book_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="book_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="book_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="book_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="book_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="naep-math-automated-scoring-challenge-overview" class="level1">
<h1>NAEP Math Automated Scoring Challenge Overview</h1>
<p>The <a href="https://nces.ed.gov/">National Center for Education Statistics (NCES)</a> of the <a href="https://ies.ed.gov">Institute of Education Sciences</a> invites researchers and assessment practitioners to develop algorithms that predict the scores given by human raters on open-ended items for NAEP mathematics assessment for students in fourth and eighth grades. The purpose of the challenge is to help NAEP to identify effective approaches, expected levels of accuracy, and methods to ensure that automated approaches do not demonstrate bias based on a student’s social context or demographic factors.</p>
<p>This Challenge requires that submissions provide predicted human scores and are transparent in their submissions by explaining the methods used to obtain those results. In addition to the score prediction challenge, participants are invited to create submissions for an “innovative interpretability challenge” that can help explain algorithm functioning and provide evidence for the validity of the algorithm in measuring student responses. Submission to the score prediction challenge (and accuracy within top 10 entries) is required for eligibility for the interpretability challenge.</p>
<section id="challenge-details" class="level2">
<h2 class="anchored" data-anchor-id="challenge-details">Challenge Details</h2>
<p><strong>Total Cash Prizes Offered</strong>:&nbsp;Maximum of $40,000 for first-place prediction entry, $20,000 for first-place interpretability entry.</p>
<p><strong>Type of Challenge</strong>:&nbsp;Automated Scoring of Mathematics<br>
Assessment Constructed Response Items using Natural Language Processing.</p>
<section id="key-dates" class="level3">
<h3 class="anchored" data-anchor-id="key-dates">Key Dates</h3>
<table class="table">
<thead>
<tr class="header">
<th>Milestone</th>
<th>Date</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Challenge Opens</td>
<td>2/21/23</td>
</tr>
<tr class="even">
<td>Application Deadline</td>
<td>3/20/23</td>
</tr>
<tr class="odd">
<td>Test Dataset Released</td>
<td>5/1/23</td>
</tr>
<tr class="even">
<td>Submission Deadline</td>
<td>5/8/23</td>
</tr>
<tr class="odd">
<td>Winners Announced</td>
<td>June 2023</td>
</tr>
</tbody>
</table>
<p><strong>An informational webinar will be held on March 7th 2023 @ 12:00 ET. Attendance at the webinar is not required to participate in the challenge.</strong></p>
<p>Advance webinar registration required at the <a href="https://www.eventbrite.com/e/rfi-for-naep-math-automated-scoring-challenge-tickets-529659705437">following URL</a>.</p>
</section>
</section>
</section>
<section id="table-of-contents" class="level1">
<h1>Table of Contents</h1>
<ol type="1">
<li><a href="#description">Description</a></li>
<li><a href="#eligibility">Eligibility</a></li>
<li><a href="#dataset">Dataset</a></li>
<li><a href="#evaluation">Evaluation-Criteria</a></li>
<li><a href="#participation">Participation-Process</a></li>
<li><a href="#submission">Submission-Instructions</a></li>
<li><a href="#prizes">Prizes</a></li>
<li><a href="#timeline">Timeline</a></li>
<li><a href="#appendix">Appendix-A-Methods</a></li>
<li><a href="#references">References</a></li>
</ol>
<section id="challenge-administration-platform" class="level2">
<h2 class="anchored" data-anchor-id="challenge-administration-platform">Challenge Administration Platform</h2>
<p>The complete announcement and application to participate in the Challenge is posted on the current <a href="https://github.com/NAEP-AS-Challenge/math-prediction">Github site</a>.</p>
<p>This platform will be used for the following purposes:</p>
<ol type="1">
<li><p><strong>Information</strong>: detailed information about the challenge will be posted here and available to the public. For updates, please “watch” the repository.</p></li>
<li><p><strong>Questions</strong>: all questions about the challenge should be posted as an issue and will be publicly available. Responses will typically be made within 24 business hours.</p></li>
</ol>
<p><strong>Please note that no data will be provided via Github nor should any submissions be posted via Github; this application is not authorized for classified data exchange by the Department of Education. Items may be discussed but no response information should be shown or shared.</strong></p>
<p>Secure server information will be provided to approved participants via the contact specified on the data application.</p>
<p><a id="description" href=""></a></p>
</section>
</section>
<section id="challenge-description" class="level1">
<h1>Challenge Description</h1>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>Automated Scoring using natural language processing (NLP) is a well-developed application of artificial intelligence in education. Results for predicting human assigned scores for essay items have been demonstrated to be on-par with the inter-rater reliability of human scorers for well-developed items (Shermis 2014). Currently, the National Assessment of Educational Progress (NAEP) includes constructed responses<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> in a large proportion of mathematics items to provide students with an opportunity to explain their reasoning or the process they used to respond to a mathematics item. While many of these items can be scored using automated rule-based methods, others contain more complex responses that cannot be accurately scored using these methods. Currently, NAEP alliance members assemble teams of human scorers who score millions of student responses to NAEP’s assessments.</p>
<p>A <a href="https://github.com/NAEP-AS-Challenge/info/blob/main/results.md">public data challenge</a> held in 2021 demonstrated that NAEP’s constructed response <em>reading items</em> can be scored successfully using natural language processing. The successful NLP approaches used in the prior challenge used large language models, which contain billions of parameters. These models are intrinsically difficult to understand by human reviewers. The inability to understand how algorithms calculate predictions makes it difficult to have confidence in the algorithm, despite high degrees of accuracy (Doshi-Velez and Kim 2017). This problem is not unique to education, and the definition of interpretability, let alone consistent criteria to achieve it, have not been established (Lipton 2018). As a result, this challenge provides an opportunity and incentive for teams to conduct additional work in this area.</p>
<p>In addition to increasing trust in prediction results, interpretability can help provide additional information about patterns observed in responses related to student math performance which can help to provide additional insights from assessment responses. Further, this information may be helpful in developing assessment items that are focused on areas of key issues.</p>
</section>
<section id="current-challenge" class="level2">
<h2 class="anchored" data-anchor-id="current-challenge">Current Challenge</h2>
<p>This challenge seeks to expand on this earlier work to ascertain how accurately automated scoring models can perform well with a representative subset of NAEP math constructed response items administered in 2017 and 2019 to students in grades 4 and 8. The ultimate goal is to produce reliable and valid score assignments, provide additional information about responses (e.g.&nbsp;common errors), and generate scores more quickly while reducing scoring costs.</p>
<p>A custom rubric and scoring guide is created for each item and used to train human scorers. Successful respondents should also build a predictive model specific to each item, using current state-of-the-art practices in natural language processing. As described more extensively in the “<a href="#dataset">Dataset</a> section, for some items the constructed response portion of the item is scored in isolation from other aspects of the response, and in other items there is an overall score in which the predicted score will incorporate results from calculations in addition to the constructed response.</p>
<p>Detailed item information is <a href="resources/item_guide.pdf">available</a> and the training guides used for human scorers are included in the classified dataset to approved participants. Training data from prior human scoring administrations will be provided for all items to participants.</p>
<p>In addition to providing a set of predicted scores for these items, successful respondents to this Challenge will provide a technical report that describes the data pre-processing, model training, and model performance information that was used to create the predicted scores. Responses must include analyses to ensure that the predictions are not systematically different from human-assigned scores by student social context or demographic information (i.e that bias is not observed); algorithm accuracy should be similar for students from all backgrounds and not exhibit bias. Student information provided includes Race/ethnicity, sex/gender, English language learner status, individualized education plans, and accommodations.</p>
<p>The Federal Government is particularly interested in submissions that provide accurate results and meet these equity goals, as they have been absent from a good deal of recent research in automated scoring, particularly for solutions using artificial intelligence (e.g., neural networks, transformer networks) and other complex algorithmic approaches (Kumar and Boulanger 2020).</p>
<p>Both the technical report and predicted scores will be submitted simultaneously. The report will be evaluated before respondents’ predicted score submissions are evaluated. Only reports that meet acceptance criteria (as specified under “evaluation criteria”) will be considered as valid submissions and evaluated for accuracy of the predicted scores compared to the hold-out test dataset.</p>
<p>This process is consistent with the operational processes that the Department intends to use in future applications of automated scoring and artificial intelligence; only models that can provide substantive validity evidence and demonstrate that bias is not observed would be approved for purchase and use.</p>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-doshi-velez2017" class="csl-entry" role="doc-biblioentry">
Doshi-Velez, Finale, and Been Kim. 2017. “Towards A Rigorous Science of Interpretable Machine Learning.” <em>arXiv:1702.08608</em> <span class="math display">\[Cs, Stat\]</span>, March. <a href="http://arxiv.org/abs/1702.08608" class="uri">http://arxiv.org/abs/1702.08608</a>.
</div>
<div id="ref-kumar2020" class="csl-entry" role="doc-biblioentry">
Kumar, Vivekanandan, and David Boulanger. 2020. “Explainable Automated Essay Scoring: Deep Learning Really Has Pedagogical Value.” <em>Frontiers in Education</em> 5 (October): 572367. <a href="https://doi.org/10.3389/feduc.2020.572367" class="uri">https://doi.org/10.3389/feduc.2020.572367</a>.
</div>
<div id="ref-liptonMythosModelInterpretability2018" class="csl-entry" role="doc-biblioentry">
Lipton, Zachary C. 2018. “The Mythos of Model Interpretability: In Machine Learning, the Concept of Interpretability Is Both Important and Slippery.” <em>Queue</em> 16 (3): 31–57. <a href="https://doi.org/10.1145/3236386.3241340" class="uri">https://doi.org/10.1145/3236386.3241340</a>.
</div>
<div id="ref-shermisStateoftheartAutomatedEssay2014" class="csl-entry" role="doc-biblioentry">
Shermis, Mark D. 2014. “State-of-the-Art Automated Essay Scoring: Competition, Results, and Future Directions from a United States Demonstration.” <em>Assessing Writing</em> 20 (April): 53–76. <a href="https://doi.org/10.1016/j.asw.2013.04.001" class="uri">https://doi.org/10.1016/j.asw.2013.04.001</a>.
</div>
</div>
<p><a id="eligibility" href=""></a></p>
</section>
<section id="eligibility-information" class="level2">
<h2 class="anchored" data-anchor-id="eligibility-information">Eligibility Information</h2>
<p>Institutions and individuals that have the ability and capacity to conduct research are eligible to apply. Eligible applicants include, but are not limited to, nonprofit and for-profit organizations and public and private agencies and institutions, such as colleges and universities. Due to prior access to the items and test data, current NAEP Alliance member organizations are not eligible to participate. Organizations must be located within the United States due to data privacy requirements. In addition to these criteria, organizations must demonstrate the following: <a href="#_ftn1"><span class="math display">\[1\]</span></a></p>
</section>
<section id="requirements" class="level2">
<h2 class="anchored" data-anchor-id="requirements">Requirements</h2>
<ol type="1">
<li><p><strong>Prior Experience with Sensitive Data.</strong> Applicants must have prior experience handling confidential federal or education data data in a secure manner. Relevant experience includes (but is not limited to): collecting, processing, and or/analyzing confidential data on contract with a U.S. government agency; prior successful application for an IES restricted-use data license; approval to analyze confidential data at other federal agencies (for example, to access data within a Federal Statistical Research Data Center (FSRDC); agreements with K-12 school district/state departments of education to access confidential or classified data; or agreements with other local or federal agencies to safely process confidential data.</p></li>
<li><p><strong>Secure Data Handling Procedures</strong>. Applicants must meet minimum computer security requirements as specified in the “security plan for remote access to NAEP Materials” document. Please note that there are reductions to the requirements given the web-based and distributed nature of automated scoring work. Fields marked as “NA” are not applicable and do not need to be completed.</p></li>
<li><p><strong>Confidentiality Agreement &amp; Notarized Affidavit of Non-Disclosure</strong>. For more information, please see the appropriate document.</p></li>
</ol>
<section id="requirements-for-participation-confidential-data-security" class="level3">
<h3 class="anchored" data-anchor-id="requirements-for-participation-confidential-data-security">Requirements for Participation &amp; Confidential Data Security</h3>
<p>The datasets used for this challenge contain student responses from previous NAEP assessments and are therefore considered NCES confidential materials. All participants must confirm that they are able to meet NCES Confidential Data security requirements, submit non-disclosure agreements about student responses, and confidentiality agreements. These requirements include restrictions on the use of data, security of data, and destruction of data when the analysis is completed. Data must also be destroyed/deleted within 30 days of completing the Challenge and all participants must submit a signed and witnessed form confirming that action. This form is also included within the security application.</p>
<p>These confirmations and documentation of secure data handling requirements must be documented in the “<a href="resources/data-application.zip">NAEP Secure Data Access Application</a>”. This application must be completed and approved by IES personnel before an applicant will be provided access to the response data. Completed applications (please enrypt before transmission) should be sent to: <a href="mailto:automated-scoring-challenge@ed.gov?subject=Math%20Challenge">automated-scoring-challenge@ed.gov</a>.</p>
<p>Directly identifying personal information is not provided for use in analyses. It is possible, although extremely unlikely, that responses may contain personal information about individual respondents or the contexts in which they learn. Should any individually identifiable information about students, their families, and their schools be identified in the responses, it must be reported to NCES immediately and removed from any modeling activity or analysis.</p>
<p>No person may:</p>
<ul>
<li><p>Use data for any purpose other than the completion of this challenge</p></li>
<li><p>Make any publication without prior review and approval by IES. This review is conducted with particular attention to ensure that no individual person in the research sample can be identified in the publication.</p></li>
</ul>
<p>The <em>Education Sciences Reform Act of 2002</em> requires IES to develop and enforce standards to protect the confidentiality of students, their families, and their schools in the collection, reporting, and publication of data. The IES confidentiality statute is found in 20 U.S.C. 9573. Anyone who violates the confidentiality provisions of this Act when using the data may be found guilty of a class E felony and can be imprisoned for up to 5 years, and/or fined up to $250,000.</p>
<p>No future NAEP contract work is guaranteed on the basis of performance in this competition.</p>
<hr>
<p><a href="#_ftnref1"><span class="math display">\[1\]</span></a>Individuals at selected organizations must access and analyze the data in the United States but they do not need to be U.S. citizens or residents. For example, a foreign student at a U.S.-based university may participate in the challenge as long as they are analyzing the data from within the United States.</p>
</section>
</section>
<section id="eligibility-information-1" class="level2">
<h2 class="anchored" data-anchor-id="eligibility-information-1">Eligibility Information</h2>
<p>Institutions and individuals that have the ability and capacity to conduct research are eligible to apply. Eligible applicants include, but are not limited to, nonprofit and for-profit organizations and public and private agencies and institutions, such as colleges and universities. Due to prior access to the items and test data, current NAEP Alliance member organizations are not eligible to participate. Organizations must be located within the United States due to data privacy requirements. In addition to these criteria, organizations must meet the following criteria:</p>
</section>
<section id="requirements-1" class="level2">
<h2 class="anchored" data-anchor-id="requirements-1">Requirements</h2>
<ol type="1">
<li><p><strong>Prior Experience with Sensitive Data.</strong> Applicants must have prior experience handling confidential federal or education data data in a secure manner. Relevant experience includes (but is not limited to): collecting, processing, and or/analyzing confidential data on contract with a U.S. government agency; prior successful application for an IES restricted-use data license; approval to analyze confidential data at other federal agencies (for example, to access data within a Federal Statistical Research Data Center (FSRDC); agreements with K-12 school district/state departments of education to access confidential or classified data; or agreements with other local or federal agencies to safely process confidential data.</p></li>
<li><p><strong>Secure Data Handling Procedures</strong>. Applicants must meet minimum computer security requirements as specified in the “security plan for remote access to NAEP Materials” document. Please note that there are reductions to the requirements given the web-based and distributed nature of automated scoring work.</p></li>
<li><p><strong>Confidentiality Agreement &amp; Notarized Affidavit of Non-Disclosure</strong>. For more information, please see the appropriate document.</p></li>
</ol>
<section id="requirements-for-participation-confidential-data-security-1" class="level3">
<h3 class="anchored" data-anchor-id="requirements-for-participation-confidential-data-security-1">Requirements for Participation &amp; Confidential Data Security</h3>
<p>The datasets used for this challenge contain student responses from previous NAEP assessments and are therefore considered NCES confidential materials. All participants must confirm that they are able to meet NCES Confidential Data security requirements, submit non-disclosure agreements about student responses, and confidentiality agreements. These requirements include restrictions on the use of data, security of data, and destruction of data when the analysis is completed. Data must also be destroyed/deleted within 30 days of completing the Challenge and all participants must submit a signed and witnessed form confirming that action. This form is also included within the security application.</p>
<p>These confirmations and documentation of secure data handling requirements must be documented in the “<a href="data-application.zip">NAEP Secure Data Access Application</a>”. This application must be completed and approved by IES personnel before an applicant will be provided access to the response data. Completed responses (please enrypt before transmission) should be sent to: <a href="mailto:automated-scoring-challenge@ed.gov?subject=Math%20Challenge">automated-scoring-challenge@ed.gov</a>.</p>
<p>Directly identifying personal information is not provided for use in analyses. It is possible, although extremely unlikely, that responses may contain personal information about individual respondents or the contexts in which they learn. Should any individually identifiable information about students, their families, and their schools be identified in the responses, it must be reported to NCES immediately and removed from any modeling activity or analysis.</p>
<p>No person may:</p>
<ul>
<li><p>Use data for any purpose other than the completion of this challenge</p></li>
<li><p>Make any publication without prior review and approval by IES. This review is conducted with particular attention to ensure that no individual person in the research sample can be identified in the publication.</p></li>
</ul>
<p>The <em>Education Sciences Reform Act of 2002</em> requires IES to develop and enforce standards to protect the confidentiality of students, their families, and their schools in the collection, reporting, and publication of data. The IES confidentiality statute is found in 20 U.S.C. 9573. Anyone who violates the confidentiality provisions of this Act when using the data may be found guilty of a class E felony and can be imprisoned for up to 5 years, and/or fined up to $250,000.</p>
<p>No future NAEP contract work is guaranteed on the basis of performance in this competition.</p>
<hr>
<p><a href="#_ftnref1"><span class="math display">\[1\]</span></a> Individuals at selected organizations must access and analyze the data in the United States but they do not need to be U.S. citizens or residents. For example, a foreign student at a U.S.-based university may participate in the challenge as long as they are analyzing the data from within the United States.</p>
<p><a id="dataset" href=""></a></p>
</section>
</section>
<section id="dataset-description" class="level2">
<h2 class="anchored" data-anchor-id="dataset-description">Dataset Description</h2>
<p>Participants will be provided access to digital files that contain information related to the assessment items, the scoring guides used to train human raters, and response data that includes XML-formatted text, human assigned scores, and demographic information about the respondent. The responses correspond to items which assess student knowledge and ability in a variety of content areas and complexity levels.</p>
<p>Information for 10 items will be provided for this challenge and eligible entries will provide predicted scores for every student response. These items have been reviewed to ensure that the content is appropriate to natural language processing (e.g.&nbsp;“explain your answer”) and that there is sufficient distribution of responses to provide a meaningful prediction challenge. The data will be split into a training dataset and a test dataset.</p>
<p>The training dataset will be provided first and then a test dataset (with responses only) will be provided <strong>one week</strong> before the challenge deadline. Detailed information about responses included for each item is provided in the “Variables with different meanings for each item” section below and in the scoring guides included in the “<a href="data/Item%20information.zip"><em>Item information.zip</em></a>” file.</p>
</section>
<section id="data-file-information" class="level2">
<h2 class="anchored" data-anchor-id="data-file-information">Data File Information</h2>
<p>Data for the competition has been aggregated into a single file from multiple test items. For this challenge you will be using items from the grade 4 and grade 8 NAEP Math Assessments that were administered in 2017 and 2019. Information about the aggregated file and how it was prepared, along with general instructions for the challenge and data handling rules are contained below. Questions about the challenge should be posted to the Github “issues” page for the challenge: <a href="https://github.com/naep-as-challenge" class="uri">https://github.com/naep-as-challenge</a></p>
</section>
<section id="variables-common-to-all-items" class="level2">
<h2 class="anchored" data-anchor-id="variables-common-to-all-items">Variables Common to All Items</h2>
<p>Some variables about the item, responses, and respondent were available for all items in the source data. Those variables are described in the table below.</p>
<table class="table">
<colgroup>
<col style="width: 5%">
<col style="width: 33%">
<col style="width: 2%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Variable</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Type</th>
<th style="text-align: left;">Values (if constrained)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">student_id</td>
<td style="text-align: left;">pseudonymous student ID – not linkable across item-years</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">e.g.&nbsp;“xYzq4StVaC”</td>
</tr>
<tr class="even">
<td style="text-align: left;">accession</td>
<td style="text-align: left;">Item number</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">e.g.&nbsp;“VH139087”</td>
</tr>
<tr class="odd">
<td style="text-align: left;">score_to_predict</td>
<td style="text-align: left;">Outcome to predict</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">e.g.&nbsp;1, 2, 3</td>
</tr>
<tr class="even">
<td style="text-align: left;">predict_from</td>
<td style="text-align: left;">Text related to “score_to_predict”</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">“Because A&gt;B”</td>
</tr>
<tr class="odd">
<td style="text-align: left;">year</td>
<td style="text-align: left;">Year assessment was administered</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">2017, or 2019</td>
</tr>
<tr class="even">
<td style="text-align: left;">srace10</td>
<td style="text-align: left;">Student’s race reported by the school</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">(1=‘White, not Hispanic’, 2=‘Afric Amer, not Hisp’, 3=‘Hispanic of any race’, 4=‘Asian, not Hispanic’, 5=‘Amer Ind/Alaska Nat’, 6=‘Native Ha/Pac Island’, 7=‘&gt;1 race, not Hispanic’)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">dsex</td>
<td style="text-align: left;">Student’s sex</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">1=male, 2=female</td>
</tr>
<tr class="even">
<td style="text-align: left;">accom2</td>
<td style="text-align: left;">Student accommodations. Note: Item VH304954 did not have accom2 so for this item accom2 is entirely NA.</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">1=‘Accommodated’, 2=‘Not accommodated’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">iep</td>
<td style="text-align: left;">IEP</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">1=SD, 2=Not SD</td>
</tr>
<tr class="even">
<td style="text-align: left;">lep</td>
<td style="text-align: left;">English learner status</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">1=English Learner, 2=Not English Learner</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rater_1</td>
<td style="text-align: left;">Score given by human rater (component-scored items only)</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">e.g.&nbsp;1A, 2B, 3A …</td>
</tr>
<tr class="even">
<td style="text-align: left;">pta_rtr1</td>
<td style="text-align: left;">Part A human rater score (composite items only)</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">e.g.&nbsp;1, 2A, 2, 3A …</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ptb_rtr1</td>
<td style="text-align: left;">Part B human rater score (composite items only)</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">e.g.&nbsp;1, 2A, 2, 3A …</td>
</tr>
<tr class="even">
<td style="text-align: left;">ptc_rtr1</td>
<td style="text-align: left;">Part C human rater score (composite items only)</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">e.g.&nbsp;1, 2A, 2, 3A …</td>
</tr>
<tr class="odd">
<td style="text-align: left;">composite</td>
<td style="text-align: left;">Composite score (atomic-scored items only)</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">e.g.&nbsp;1, 2, 3</td>
</tr>
<tr class="even">
<td style="text-align: left;">score</td>
<td style="text-align: left;">Score (containing partial credit codes)</td>
<td style="text-align: left;">string</td>
<td style="text-align: left;">e.g.&nbsp;1A, 2B, 3A …</td>
</tr>
<tr class="odd">
<td style="text-align: left;">assigned_score</td>
<td style="text-align: left;">Simplified numeric score total for item (1, 2, 3…) from either “rater_1” or “composite”</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">1, 2, 3 …</td>
</tr>
<tr class="even">
<td style="text-align: left;">ee_use</td>
<td style="text-align: left;">Item used equation editor</td>
<td style="text-align: left;">integer</td>
<td style="text-align: left;">0=no EE use, 1=EE use</td>
</tr>
</tbody>
</table>
</section>
<section id="data-processing-information" class="level2">
<h2 class="anchored" data-anchor-id="data-processing-information">Data Processing Information</h2>
<p>There are four “Type II” items which were composed of multiple sub-items or parts that each have their own set of scores and response fields. For the purpose of the challenge, participants are requested to score the combined overall score (<code>score_to_predict</code>), based on the constructed response component which we believe is the most salient (<code>predict_from</code>), using NLP. For the six other items, called “Type I” items here, there are multiple parts within an item; however, these parts are considered dependently linked portions of the item and, as such, were assigned a single score that encompasses the responses contained within both parts.</p>
<p>For the “Type II” items, the sub-item scores have been combined into a single “assigned_score” variable which is described in the common variables table above. The original part scores are also included and can be decoded using the item scoring guides provided in “<a href="data/Item%20information.zip"><em>Item information.zip</em></a>” which will be provided to participants with the responses upon approval of the data application.</p>
<p>Note that this composite variable is <em>not</em> always the outcome which contestants should predict. To make it clear which outcome contestants should predict, we’ve created a variable “<code>score_to_predict</code>” which is the field which will be used as the outcome variable to create predicted scores for. We’ve also created a variable named “<code>predict_from</code>” to identify the text with the most relevant constructed response text to use when creating predicted scores.</p>
<p>The original item data contained extended constructed response and short constructed response (ECR and CR) text, item selections for multiple choice, and some process data (such as response “eliminations” for CR items) embedded within a json data structure, with MathML (XML) equation editor codes nested inside. The original test item data had different XML structures for each item, and within item there are differences in the XML coding between the year of administration. <strong>These differences may impact how predictive models will perform across years.</strong></p>
<p>These data have been parsed to make them easier to process. The parsed XML data, in contrast to the common variables listed above, are different for each item. The item specific variables are described below the item name in the list that follows. Please note, the format of the data values for the process data (e.g.&nbsp;eliminations) may differ by year for the same item. For example, eliminations may be recorded as “(1, 2, 5)” in 2017 and “1, 2, 5” in 2019.</p>
<p>Also note, the CR text has been parsed but not completely cleaned. The data was analyzed for sensitive information (e.g.&nbsp;personally-identifiable information, profanity, toxic language) and some responses were removed as a result. However, spellcheck has not been applied to correct what may be obvious spelling errors.</p>
</section>
<section id="variables-with-different-meanings-for-each-item" class="level2">
<h2 class="anchored" data-anchor-id="variables-with-different-meanings-for-each-item">Variables with different meanings for each item</h2>
<p>Please consult the scoring guides included in “<a href="data/Item%20information.zip"><em>Item information.zip</em></a>” to map the fields below to the question areas.</p>
<section id="for-item-vh134067" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh134067">For item VH134067</h4>
<p><strong>parsed_xml_v1</strong>– Text for ECR item response. <br> <br></p>
</section>
<section id="for-item-vh139380" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh139380">For item VH139380</h4>
<p><strong>parsed_xml_v1</strong>– SCR text <br><br>
<strong>parsed_xml_v2</strong>– ECR text <br> <br></p>
</section>
<section id="for-item-vh266015" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh266015">For item VH266015</h4>
<p><strong>source1</strong>– drag and drop tile “from” <br><br>
<strong>source2</strong>– drag and drop tile “from” <br><br>
<strong>source3</strong>– drag and drop tile “from” <br><br>
<strong>source4</strong>– drag and drop tile “from” <br><br>
<strong>target1</strong>– drag and drop tile “to” <br><br>
<strong>target2</strong>– drag and drop tile “to” <br><br>
<strong>target3</strong>– drag and drop tile “to” <br><br>
<strong>target4</strong>– drag and drop tile “to” <br><br>
<strong>parsed_xml_v1</strong>– CR text <br> <br></p>
</section>
<section id="for-item-vh266510" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh266510">For item VH266510</h4>
<p><strong>parsed_xml_v1</strong>– ECR text <br><br>
<strong>selected</strong>– MC radio button choices as a logical vector (e.g.&nbsp;“FALSE FALSE TRUE FALSE”) for 2019 only. <br><br>
<strong>eliminations</strong>– MC item eliminations as a variable length numeric vector (e.g., c(1,3,4)) for 2017 only. <br><br>
<strong>eliminated</strong>– MC item eliminations as a length 4 logical vector (e.g., TRUE FALSE FALSE TRUE) for 2019 only. <br> <br></p>
</section>
<section id="for-item-vh269384" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh269384">For item VH269384</h4>
<p><strong>selected1</strong>– 1st MC item option radio button 1 <br><br>
<strong>selected2</strong>– 1st MC item option radio button 2 <br><br>
<strong>selected3</strong>– 1st MC item option radio button 3 <br><br>
<strong>selected4</strong>– 1st MC item option radio button 4 <br><br>
<strong>selected1.1</strong>– 2nd MC item option radio button 1 <br><br>
<strong>selected2.1</strong>– 2nd MC item option radio button 2 <br><br>
<strong>eliminated1</strong>– 1st MC item elimination option radio button 1 <br><br>
<strong>eliminated2</strong>– 1st MC item elimination option radio button 2 <br><br>
<strong>eliminated3</strong>– 1st MC item elimination option radio button 3 <br><br>
<strong>eliminated4</strong>– 1st MC item elimination option radio button 4 <br><br>
<strong>eliminated1.1</strong>– 2nd MC item elimination option radio button 1 <br><br>
<strong>eliminated2.1</strong>– 2nd MC item elimination option radio button 2 <br><br>
<strong>parsed_xml_v1</strong>– ECR text <br> <br></p>
</section>
<section id="for-item-vh271613" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh271613">For item VH271613</h4>
<p><strong>partA_response_val</strong>– 1st MC item drop down menu selections as numeric vector (e.g.&nbsp;c(“1”,“1”)) in 2017, and a fixed length logical vector in 2019. <br><br>
<strong>partB_response_val</strong>– 2nd MC item radio button selections as vector (e.g.&nbsp;c(“1”,““)) in 2017, and a fixed length logical vector in 2019. <br><br>
<strong>partB_eliminations</strong>– MC item eliminations for part B, format differs by year. <br><br>
<strong>parsed_xml_v1</strong>– ECR text <br><br>
<em>Note</em>– For both the response values and the eliminations, the format of the data changes between 2017 and 2019. In 2017, eliminations are stored as list of numbers, perhaps in chronological order (e.g.,”1”, “2”, but also “2–1” and “1–2”). In 2019 the responses and eliminations are stored as fixed length logical vectors (e.g., “TRUE TRUE”). <br> <br></p>
</section>
<section id="for-item-vh302907" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh302907">For item VH302907</h4>
<p><strong>parsed_xml_v1</strong>– ECR text <br><br>
<strong>parsed_xml_v2</strong>– CR text <br><br>
<strong>parsed_xml_v3</strong>– CR text <br> <br></p>
</section>
<section id="for-item-vh304954" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh304954">For item VH304954</h4>
<p><strong>parsed_xml_v1</strong>– CR text <br><br>
<strong>parsed_xml_v2</strong>– CR text <br> <br></p>
</section>
<section id="for-item-vh507804" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh507804">For item VH507804</h4>
<p><strong>source1</strong>– drag and drop tile “from” <br><br>
<strong>source2</strong>– drag and drop tile “from” <br><br>
<strong>source3</strong>– drag and drop tile “from” <br><br>
<strong>target1</strong>– drag and drop tile “to” <br><br>
<strong>target2</strong>– drag and drop tile “to” <br><br>
<strong>target3</strong>– drag and drop tile “to” <br><br>
<strong>parsed_xml_v1</strong>– CR text <br> <br></p>
</section>
<section id="for-item-vh525628" class="level4">
<h4 class="anchored" data-anchor-id="for-item-vh525628">For item VH525628</h4>
<p><strong>source1</strong>– drag and drop tile “from” <br><br>
<strong>source2</strong>– drag and drop tile “from” <br><br>
<strong>source3</strong>– drag and drop tile “from” <br><br>
<strong>source4</strong>– drag and drop tile “from” <br><br>
<strong>target1</strong>– drag and drop tile “to” <br><br>
<strong>target2</strong>– drag and drop tile “to” <br><br>
<strong>target3</strong>– drag and drop tile “to” <br><br>
<strong>target4</strong>– drag and drop tile “to” <br><br>
<strong>parsed_xml_v1</strong>– CR text <br></p>
</section>
</section>
<section id="information-about-constructed-response-fields" class="level2">
<h2 class="anchored" data-anchor-id="information-about-constructed-response-fields">Information about constructed response fields</h2>
<p>Many items include one or more constructed response. While many of these are short, non-textual responses like equations, the following plots provide some information about the distribution of word and character counts found in the these responses. <br><br>
<br></p>
<p><img src="files_for_readme/word_count_boxplot.png" alt="Word count (excluding numbers and symbols)" style="width:80.0%"> <br><br>
<img src="files_for_readme/word_count_wmaths_boxplot.png" alt="Word count with numbers and symbols" style="width:80.0%"> <br></p>
</section>
<section id="inter-rater-reliability" class="level2">
<h2 class="anchored" data-anchor-id="inter-rater-reliability">Inter-rater Reliability</h2>
<p>Approximately 5% of the NAEP item responses were double scored. Quadradic Weighted Kappa (QWK) was calculated to estimate the inter-rater reliability for the double-scored responses. The inter-rater reliability estimates for all items are presented below.</p>
<table class="table">
<caption>N Counts for Test/Train Split</caption>
<thead>
<tr class="header">
<th style="text-align: left;">item</th>
<th style="text-align: center;">QWK</th>
<th style="text-align: center;">score type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">VH134067</td>
<td style="text-align: center;">0.966</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH139380</td>
<td style="text-align: center;">0.981</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VH266015</td>
<td style="text-align: center;">0.963</td>
<td style="text-align: center;">Type II</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH266510</td>
<td style="text-align: center;">0.933</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VH269384</td>
<td style="text-align: center;">0.970</td>
<td style="text-align: center;">Type II</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH271613</td>
<td style="text-align: center;">0.975</td>
<td style="text-align: center;">Type II</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VH302907</td>
<td style="text-align: center;">0.980</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH304954</td>
<td style="text-align: center;">0.984</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VH507804</td>
<td style="text-align: center;">0.991</td>
<td style="text-align: center;">Type II</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH525628</td>
<td style="text-align: center;">0.956</td>
<td style="text-align: center;">Type I</td>
</tr>
</tbody>
</table>
</section>
<section id="suppression" class="level2">
<h2 class="anchored" data-anchor-id="suppression">Suppression</h2>
<p>To minimize the risk of statistical disclosure, suppression was applied to demographic variables. To minimize the impact of suppression and algorithm was developed which prioritized which of the suppression variables were set to missing (NA). The suppression variables, listed in the order in which they were prioritized, were the following: “dsex”, “iep”, “accom2”, “lep”, and “srace10”. The variable “year” was <em>not</em> included in the suppression. <br></p>
</section>
<section id="item-splits" class="level2">
<h2 class="anchored" data-anchor-id="item-splits">Item Splits</h2>
<p>The table that follows shows the N counts for the test and training data sets. <br></p>
<table class="table">
<caption>N Counts for Test/Train Split</caption>
<thead>
<tr class="header">
<th style="text-align: left;">item</th>
<th style="text-align: right;">QWK</th>
<th style="text-align: right;">min</th>
<th style="text-align: right;">max</th>
<th style="text-align: right;">test</th>
<th style="text-align: right;">train</th>
<th style="text-align: center;">score type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">VH134067</td>
<td style="text-align: right;">0.966</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">4,483</td>
<td style="text-align: right;">40,343</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH139380</td>
<td style="text-align: right;">0.981</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">2,018</td>
<td style="text-align: right;">18,157</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VH266015</td>
<td style="text-align: right;">0.963</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">1,776</td>
<td style="text-align: right;">15,987</td>
<td style="text-align: center;">Type II</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH266510</td>
<td style="text-align: right;">0.933</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4,296</td>
<td style="text-align: right;">38,667</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VH269384</td>
<td style="text-align: right;">0.970</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">1,758</td>
<td style="text-align: right;">15,826</td>
<td style="text-align: center;">Type II</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH271613</td>
<td style="text-align: right;">0.975</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">3,096</td>
<td style="text-align: right;">27,858</td>
<td style="text-align: center;">Type II</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VH302907</td>
<td style="text-align: right;">0.980</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">4,241</td>
<td style="text-align: right;">38,173</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH304954</td>
<td style="text-align: right;">0.984</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">2,743</td>
<td style="text-align: right;">24,686</td>
<td style="text-align: center;">Type I</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VH507804</td>
<td style="text-align: right;">0.991</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">1,827</td>
<td style="text-align: right;">16,443</td>
<td style="text-align: center;">Type II</td>
</tr>
<tr class="even">
<td style="text-align: left;">VH525628</td>
<td style="text-align: right;">0.956</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">1,808</td>
<td style="text-align: right;">16,275</td>
<td style="text-align: center;">Type I</td>
</tr>
</tbody>
</table>
<!-- cb-air: Is the "evaluation criteria" line below supposed to display as it does? -->
<p><a id="evaluation" href=""></a> Evaluation Criteria ================</p>
</section>
<section id="prediction-challenge" class="level2">
<h2 class="anchored" data-anchor-id="prediction-challenge">Prediction Challenge</h2>
<p>The first challenge will predict the score assigned by a human rater as accurately as possible using natural language processing methods. There are two parts to this submission:</p>
<p><strong>Part 1: Technical Report</strong>. Submissions must provide a technical report that explains their analysis process. This report should include data pre-processing steps and decisions (e.g.&nbsp;spelling correction, data transformations), model development choices, and model performance information. The report should include results appropriate to a technical audience with educational measurement expertise. These reports will be submitted simultaneously with submissions of predicted scores and must be approved before submissions are considered valid entries into the challenge. At the discretion of the reviewers, clarifications may be requested if required to meet the criteria.</p>
<p>It is not expected that competitors will reveal confidential information, but responses must provide evidence that enables an external scientific reviewer to assess the rigor, validity and fairness of the submission.</p>
<p>Technical reports will be evaluated according to three criteria, which will be equally weighted in the review:</p>
<ul>
<li><p><em>Transparency</em> – explanation of the process for data processing, model training and testing, the features extracted from the text, and the algorithms used in model building. While these may describe a general workflow, they should also include the specific text features and algorithms used to create the score predictions in this Challenge. Submissions are invited to describe the iterative process of model selection and evaluation, including the tradeoffs and decisions made during analysis.</p></li>
<li><p><em>Fairness</em> – analysis into any differences based on student demographic background in automated scoring compared to those found in human-scored results. At a minimum, the analyses should compare the standardized mean difference in scores between human and predicted scores for the criteria indicated under “scoring model accuracy” below.</p></li>
<li><p><em>Insights -</em> in conducting modeling and reviewing results, it is likely that respondents will gain insights about the student responses and items that provide additional information about the responses or suggestions to improve future item writing and scoring. We invite technical reports to include this information along with their submissions. We are particularly interested in which items were harder to score and reasons for these results.</p></li>
</ul>
<p>In addition to this analysis, core fairness analyses may include additional conventional and proven measures such as:</p>
<ul>
<li><p>Comparison of rater agreement: compare human to human with human to machine rater agreement overall and for each of the demographic groups of interest (Bridgeman, Trapani, and Attali 2012).</p></li>
<li><p>ANOVA Model: a linear model can be created which compares human rater to machine raters to evaluate if there is a systematic variance between the two methods of scoring (Justice 2022).</p></li>
<li><p>T-test: For any two suspected demographic groups that have suspected scoring differences, a simple t-test can be performed to see if there any statistically significant differences between these two groups (Penfield 2016) and whether that association is different between human and machine scoring.</p></li>
</ul>
<p>Although not an evaluated criteria for winning the competition, technical reports should provide estimates for minimal training sample sizes that would place the scoring engine’s estimates within two percent of the final predicted values.</p>
<p><strong>Part 2: Scoring Model Accuracy</strong>. Items vary widely in their suitability for automated scoring. To evaluate submissions for their potential operational use, scoring performance of teams will be evaluated based on the following criteria:</p>
<p><strong>Primary Criteria: Number of items meeting automated scoring accuracy thresholds</strong>. Submissions will be analyzed for item-level accuracy. Response predictions will be grouped by item, then compared to the scores given by the human rater of record. NCES will calculate accuracy using quadratic weighted kappa (rounded to the third decimal place). Competitors must score all submitted responses or those predictions will be considered incorrect.</p>
<p>Two thresholds must be achieved for an item to be deemed “sufficiently accurate”:</p>
<ol type="1">
<li><p><strong>Prediction compared to human agreement</strong>. The model to human agreement must be within QWK 0.05 of the human inter-rater reliability for the same item (as specified in the “Dataset” section);</p></li>
<li><p><strong>Results do not demonstrate bias.</strong> Standardized mean differences (SMD) in scores by student social context and demographic information are less than 0.10. Analyses will be conducted based on the following criteria (which are included in the training dataset): student’s race reported by the school, student’s sex, student accommodations, English learner status, Individualized Education Plan. The formula to calculate SMD is provided in Appendix A.</p></li>
</ol>
<p>These threshold levels may be changed based on submitted results at the discretion of NCES. Items meeting these submissions will be counted and the response with the most items meeting these requirements will be deemed the winner.</p>
<p><strong>Secondary Criteria: Average Scoring Accuracy at Item-Level.</strong> In the case that there is a tie, average scoring accuracy by item will be used as a secondary criterion. Submissions will be rank-ordered first by number of items scorable, and then ordered by the average scoring accuracy by item.</p>
<p>Reviewers reserve the right to make final decisions on awards considering the potential for very close scores and potential additional factors considered in choosing an optimal model (e.g.&nbsp;exact agreement, score distributions, fairness analysis results).</p>
</section>
<section id="innovative-interpretability-challenge" class="level2">
<h2 class="anchored" data-anchor-id="innovative-interpretability-challenge">Innovative Interpretability Challenge</h2>
<p>In addition to the score prediction challenge, participants are invited to submit a response that includes additional analyses, visualizations, and explanations that provide evidence as to the validity of the model in replicating human scoring processes. Responses should address both of the following areas of interpretability as defined in (Lipton 2018).</p>
<ul>
<li><p><strong>Simulatability</strong> - representation of overall model performance that can be understood by humans in terms of how the predictions are related to the constructs being assessed. These analyses should demonstrate performance across population groups that include demographic subgroups.</p></li>
<li><p><strong>Post-Hoc Measures -</strong> in addition to representing the overall model, post-hoc measures should be included which compare the model performance to other individual (or combined) features that are not included in the model itself.</p></li>
</ul>
<section id="evaluation-criteria" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-criteria">Evaluation Criteria</h3>
<p>The following criteria will be used to evaluate interpretability submissions:</p>
<ul>
<li><p><strong>Construct Coverage</strong> (50%) - how completely does the submission cover the constructs that are included in scoring rubrics? Is the coverage proximate or a distant approximation of the constructs that are included? How well does the response provide evidence that could build trust in the performance of the model?</p></li>
<li><p><strong>Subpopulation analyses</strong> (25%) - how thoroughly do the analyses examine potential differential effects on populations as indicated by demographic criteria? Singular criteria analyses are required in the technical report for the prediction challenge; this innovation challenge should use more complex methods which consider the intersections of these identities and may be informed by conceptual ideas about student populations, results of subpopulation analyses, or both. How well do the analyses consider the diversity of student backgrounds and potential ways in which bias might be present in an algorithm?</p></li>
<li><p><strong>Clarity</strong> (25%) - how intuitive is the submission (assuming an expert reader)? Does it include visualizations, statistics and other features of effective scientific presentations? Or does it require substantial time and effort to understand?</p></li>
</ul>
<p>Responses to the interpretability challenge should be included in a separate section within the technical report.</p>
<div class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-bridgeman2012" class="csl-entry" role="doc-biblioentry">
Bridgeman, Brent, Catherine Trapani, and Yigal Attali. 2012. “Comparison of Human and Machine Scoring of Essays: Differences by Gender, Ethnicity, and Country.” <em>Appl. Meas. Educ.</em> 25 (1): 27—40. <a href="https://doi.org/10.1080/08957347.2012.635502" class="uri">https://doi.org/10.1080/08957347.2012.635502</a>.
</div>
<div id="ref-justice2022" class="csl-entry" role="doc-biblioentry">
Justice, Derek. 2022. “A Linear Model Approach to Bias Detection.” In <em>Proceedings of the National Council on Measurement in Education</em>. San Diego, California, United States.
</div>
<div id="ref-lipton2018" class="csl-entry" role="doc-biblioentry">
Lipton, Zachary C. 2018. “The Mythos of Model Interpretability: In Machine Learning, the Concept of Interpretability Is Both Important and Slippery.” <em>Queue</em> 16 (3): 31–57. <a href="https://doi.org/10.1145/3236386.3241340" class="uri">https://doi.org/10.1145/3236386.3241340</a>.
</div>
<div id="ref-penfield2016" class="csl-entry" role="doc-biblioentry">
Penfield, R. D. 2016. “Fairness in Test Scoring.” In <em>Fairness in Educational Assessment and Measurement</em>, edited by N. J. Dorans and L. L. Cook, 55–76. Routledge. <a href="https://www.taylorfrancis.com/books/oa-edit/10.4324/9781315774527/fairness-educational-assessment-measurement-neil-dorans-linda-cook" class="uri">https://www.taylorfrancis.com/books/oa-edit/10.4324/9781315774527/fairness-educational-assessment-measurement-neil-dorans-linda-cook</a>.
</div>
</div>
<p><a id="participation" href=""></a> Participation Process ================</p>
<p>Interested participants must begin by reviewing the eligibility criteria, timeline, and other materials and ensuring that they are well-suited to participate. Once completed, interested participants submit an application for data access to participate by first completing the required security authorization forms to access NCES Confidential materials. These are provided at: <a href="data-application.zip">data-application.zip</a>.</p>
<p>Completed data applications should be encrypted with a password and sent via email to: <a href="mailto:automated-scoring-challenge@ed.gov" class="email">automated-scoring-challenge@ed.gov</a> by the deadline as stated in the “timeline” section.</p>
<p>Please note that applications will be reviewed on a rolling basis. Once approved, participants will be provided with secure access to the dataset and materials for the challenge.</p>
<p>Submissions must be uploaded to an IES secure server. IES staff will provide access credentials and login information. Submissions should contain both the technical report and predicted scores.</p>
<p>Within 30 days of final submissions, participants are required to submit the signed and witnessed form confirming their destruction / deletion of all data that was provided for their use in this challenge.</p>
<p>All entrants consent to the Official Rules, Terms, and Conditions upon submitting an entry. Once submitted, a submission may not be altered. The Department reserves the right to disqualify any submission that the Department deems inappropriate. The Department encourages entrants to submit entries, in the form of a final, technical report, that contains both a narrative and predicted scores as far in advance of the deadline as possible.</p>
<p>Individuals with disabilities who need an accommodation or auxiliary aid in connection with the submission process should contact&nbsp;<a href="mailto:automated-scoring-challenge@ed.gov" class="email">automated-scoring-challenge@ed.gov</a>. If the Department provides an accommodation or auxiliary aid to an individual with a disability in connection with the submission process, the entry remains subject to all other requirements and limitations in this notice.</p>
<p><a id="submission" href=""></a> Submission Instructions ================</p>
<section id="valid-submissions-will-include-reports-with-the-following-items" class="level4">
<h4 class="anchored" data-anchor-id="valid-submissions-will-include-reports-with-the-following-items">Valid submissions will include reports with the following items:</h4>
<ol type="1">
<li><p>A technical report that describes the modeling process and results of fairness analysis.</p></li>
<li><p>Predicted scores (CSV format) from the test data responses (see below for data format).</p></li>
</ol>
</section>
</section>
<section id="predicted-score-data-format-and-upload-process" class="level3">
<h3 class="anchored" data-anchor-id="predicted-score-data-format-and-upload-process">Predicted Score Data Format and Upload Process</h3>
<p>To submit your predicted scores, please use the following format to modify the test dataset provided for each item.</p>
<ol type="1">
<li><p>Delete the column “predict_from” that contains the student response text (for data security reasons).&nbsp; Please do not submit any files that contain the text of student responses.</p></li>
<li><p>Add a column “predicted_score” and enter your predicted score in that column. <strong>Only one predicted score should be provided</strong>.</p></li>
<li><p>Add a column “participant” and put in the email address for the project lead contact (you only need to enter in one row).</p></li>
<li><p>Save the file using the same original filename in .CSV format.</p></li>
<li><p>Repeat for all items and save into a single folder/directory.</p></li>
<li><p>Zip that folder/directory. Add your technical report and upload to the secure site that was provided via email.</p></li>
</ol>
<p><a id="prizes" href=""></a> Prizes ================</p>
</section>
</section>
<section id="prize-information" class="level2">
<h2 class="anchored" data-anchor-id="prize-information">Prize Information</h2>
<p>The potential prize purse is up to $60,000 per team.</p>
<ul>
<li><p>The first-place prize for the <strong>prediction</strong> challenge is $40,000, with up to 2 runner-up prizes of $15,000 each.</p></li>
<li><p>The first-place prize for the <strong>interpretability analysis</strong> challenge is $20,000, with up to 2 runner-up prizes of $5,000 each.</p></li>
</ul>
<p>Participation in the prediction challenge and results that are within the 10 most accurate submissions is required for participation in the interpretability challenge.</p>
<p><a id="timeline" href=""></a> Timeline ================</p>
<table class="table">
<thead>
<tr class="header">
<th>Activity</th>
<th>Date</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Challenge Posted</td>
<td>2/21/23</td>
</tr>
<tr class="even">
<td>Request for Information Webinar</td>
<td>3/7/23</td>
</tr>
<tr class="odd">
<td>Application Deadline</td>
<td>3/20/23 at 11:59 ET</td>
</tr>
<tr class="even">
<td>Training Data Available</td>
<td>2/23/23-4/28/23</td>
</tr>
<tr class="odd">
<td>Test Data Provided</td>
<td>5/1/23</td>
</tr>
<tr class="even">
<td>Submission Deadline (Report &amp; Predictions)</td>
<td>5/8/23 <span class="citation" data-cites="at">@at</span> 11:59 ET</td>
</tr>
<tr class="odd">
<td>Winners Announced</td>
<td>June 2023</td>
</tr>
</tbody>
</table>
<p><a id="rules" href=""></a> Rules ================</p>
</section>
<section id="terms-and-conditions" class="level2">
<h2 class="anchored" data-anchor-id="terms-and-conditions">Terms and Conditions</h2>
<p>All entry information submitted to&nbsp;<a href="mailto:automated-scoring-challenge@ed.gov" class="email">automated-scoring-challenge@ed.gov</a>&nbsp;and all materials, including any copy of the submission, become property of the Department and will not be returned (See “Ownership and Licensing” for information about use of these items). Furthermore, the Department shall have no liability for any submission that is lost, intercepted, or not received by the Department. The Department assumes no liability or responsibility for any error, omission, interruption, deletion, theft, destruction, unauthorized access to, or alteration of, submissions.</p>
</section>
<section id="representations-and-warrantiesindemnification" class="level2">
<h2 class="anchored" data-anchor-id="representations-and-warrantiesindemnification">Representations and Warranties/Indemnification</h2>
<p>By participating in the Challenge, each entrant represents, warrants, and covenants as follows:</p>
<ul>
<li>The entrants are the sole authors, creators, and owners of the submission;</li>
</ul>
<p>The entrant’s submission:</p>
<ul>
<li><p>Is not the subject of any actual or threatened litigation or claim;</p></li>
<li><p>Does not, and will not, violate or infringe upon the privacy rights, publicity rights, or other legal rights of any third party; and</p></li>
<li><p>Does not contain any harmful computer code (sometimes referred to as “malware,” “viruses,” or “worms”).</p></li>
<li><p>The submission, and entrants’ implementation of the submission, does not, and will not, violate any applicable laws or regulations of the United States.</p></li>
<li><p>Entrants will indemnify, defend, and hold harmless the Department from and against all third party claims, actions, or proceedings of any kind and from any and all damages, liabilities, costs, and expenses relating to, or arising from, entrant’s submission or any breach or alleged breach of any of the representations, warranties, and covenants of entrant hereunder.</p></li>
<li><p>The Department reserves the right to disqualify any submission that the Department, in its discretion, deems to violate these Official Rules, Terms, and Conditions in this notice.</p></li>
</ul>
</section>
<section id="ownership-and-licensing" class="level2">
<h2 class="anchored" data-anchor-id="ownership-and-licensing">Ownership and Licensing</h2>
<p>Each entrant retains full ownership of the algorithmic approaches to their submission, including all intellectual property rights therein. By participating in the Challenge, each entrant hereby grants to the Department a royalty-free, nonexclusive, irrevocable, and worldwide license to reproduce, publish, produce derivative works, distribute copies to the public, perform publicly and display publicly, and/or otherwise use the technical report and predicted scores from each participant in the competition.</p>
</section>
<section id="publicity-release" class="level2">
<h2 class="anchored" data-anchor-id="publicity-release">Publicity Release</h2>
<p>By participating in the Challenge, each entrant hereby irrevocably grants to the Department the right to use the entrant’s name, likeness, image, and biographical information in any and all media for advertising and promotional purposes relating to the Challenge.</p>
</section>
<section id="disqualification" class="level2">
<h2 class="anchored" data-anchor-id="disqualification">Disqualification</h2>
<p>The Department reserves the right, in its sole discretion, to disqualify any entrant who is found to be tampering with the entry process or the operation of the Challenge, Challenge webpage, or other Challenge-related webpages; to be acting in violation of these Official Rules, Terms, and Conditions; to be acting in an unsportsmanlike or disruptive manner, or with the intent to disrupt or undermine the legitimate operation of the Challenge; or to annoy, abuse, threaten, or harass any other person; and, the Department reserves the right to seek damages and other remedies from any such person to the fullest extent permitted by law.</p>
</section>
<section id="disclaimer" class="level2">
<h2 class="anchored" data-anchor-id="disclaimer">Disclaimer</h2>
<p>The Challenge webpage contains information and resources from public and private organizations that may be useful to the reader. Inclusion of this information does not constitute an endorsement by the Department of any products or services offered or views expressed.</p>
<p>The Challenge webpage also contains hyperlinks and URLs created and maintained by outside organizations, which are provided for the reader’s convenience. The Department is not responsible for the accuracy of the information contained therein.</p>
</section>
<section id="notice-to-challenge-entrants-and-award-recipients" class="level2">
<h2 class="anchored" data-anchor-id="notice-to-challenge-entrants-and-award-recipients">Notice to Challenge Entrants and Award Recipients</h2>
<p>Attempts to notify entrants and award recipients will be made using the email address associated with the entrants’ submissions. The Department is not responsible for email or other communication problems of any kind.</p>
<p>If, despite reasonable efforts, an entrant does not respond within three days of the first notification attempt regarding selection as an award recipient (or a shorter time as exigencies may require) or if the notification is returned as undeliverable to such entrant, that entrant may forfeit the entrant’s award and associated prizes, and an alternate award recipient may be selected.</p>
<p>If any potential award recipient is found to be ineligible, has not complied with these Official Rules, Terms, and Conditions, or declines the applicable prize for any reason prior to award, such potential award recipient will be disqualified. An alternate award recipient may be selected, or the applicable award may go unawarded.</p>
</section>
<section id="datesdeadlines" class="level2">
<h2 class="anchored" data-anchor-id="datesdeadlines">Dates/Deadlines</h2>
<p>The Department reserves the right to modify any dates or deadlines set forth in these Official Rules, Terms, and Conditions or otherwise governing the Challenge.</p>
</section>
<section id="challenge-termination" class="level2">
<h2 class="anchored" data-anchor-id="challenge-termination">Challenge Termination</h2>
<p>The Department reserves the right to suspend, postpone, cease, terminate, or otherwise modify this Challenge, or any entrant’s participation in the Challenge, at any time at the Department’s discretion.</p>
</section>
<section id="general-liability-release" class="level2">
<h2 class="anchored" data-anchor-id="general-liability-release">General Liability Release</h2>
<p>By participating in the Challenge, each entrant hereby agrees that — (a) The Department shall not be responsible or liable for any losses, damages, or injuries of any kind (including death) resulting from participation in the Challenge or any Challenge-related activity, or from entrants’ acceptance, receipt, possession, use, or misuse of any prize; and (b) The entrant will indemnify, defend, and hold harmless the Department from and against all third-party claims, actions, or proceedings of any kind and from any and all damages, liabilities, costs, and expenses relating to, or arising from, the entrant’s participation in the Challenge.</p>
<p>Without limiting the generality of the foregoing, the Department is not responsible for incomplete, illegible, misdirected, misprinted, late, lost, postage-due, damaged, or stolen entries or prize notifications; or for lost, interrupted, inaccessible, or unavailable networks, servers, satellites, Internet Service Providers, webpages, or other connections; or for miscommunications, failed, jumbled, scrambled, delayed, or misdirected computer, telephone, cable transmissions or other communications; or for any technical malfunctions, failures, difficulties, or other errors of any kind or nature; or for the incorrect or inaccurate capture of information, or the failure to capture any information.</p>
<p>These Official Rules, Terms, and Conditions cannot be modified except by the Department in its sole and absolute discretion. The invalidity or unenforceability of any provision of these Official Rules, Terms, and Conditions shall not affect the validity or enforceability of any other provision. In the event that any provision is determined to be invalid or otherwise unenforceable or illegal, these Official Rules, Terms, and Conditions shall otherwise remain in effect and shall be construed in accordance with their terms as if the invalid or illegal provision were not contained herein.</p>
</section>
<section id="exercise" class="level2">
<h2 class="anchored" data-anchor-id="exercise">Exercise</h2>
<p>The failure of the Department to exercise or enforce any right or provision of these Official Rules, Terms, and Conditions shall not constitute a waiver of such right or provision.</p>
</section>
<section id="governing-law" class="level2">
<h2 class="anchored" data-anchor-id="governing-law">Governing Law</h2>
<p>All issues and questions concerning the construction, validity, interpretation, and enforceability of these Official Rules, Terms, and Conditions shall be governed by and construed in accordance with U.S. Federal law as applied in the Federal courts of the District of Columbia if a complaint is filed by any party against the Department.</p>
</section>
<section id="privacy-policy" class="level2">
<h2 class="anchored" data-anchor-id="privacy-policy">Privacy Policy</h2>
<p>By participating in the Challenge, each entrant hereby agrees that occasionally, the Department may also use the entrant’s information to contact the entrant about Federal Challenge and innovation related activities.</p>
<p>Please contact&nbsp;<a href="mailto:automated-scoring-challenge@ed.gov" class="email">automated-scoring-challenge@ed.gov</a>&nbsp;should you have any comments or questions about these Official Rules, Terms, and Conditions.</p>
</section>
<section id="other-information" class="level2">
<h2 class="anchored" data-anchor-id="other-information">Other Information</h2>
<p>Accessible Format:&nbsp;Individuals with disabilities can obtain this document and a copy of the submission package in an accessible format (e.g., braille, large print, audiotape, or compact disc) on request to&nbsp;<a href="mailto:automated-scoring-challenge@ed.gov" class="email">automated-scoring-challenge@ed.gov</a>.</p>
<p><a id="appendix" href=""></a> Appendix A: Analysis Methods &amp; Response Distributions ================</p>
<section id="quadratic-weighted-kappa" class="level3">
<h3 class="anchored" data-anchor-id="quadratic-weighted-kappa">Quadratic weighted kappa</h3>
<p>Predictive accuracy of submissions will be evaluated using quadratic weighted kappa for each item, a metric which measures the agreement between two scores. Quadratic weighted kappa allows disagreements to be weighted differently and is especially useful when codes or ratings are ordered. Three matrices are involved, the matrix of observed scores, the matrix of expected scores based on chance agreement, and the weight matrix. Weight matrix cells located on the diagonal (upper-left to bottom-right) represent agreement and thus contain zeros. Off-diagonal cells contain weights indicating the seriousness of that disagreement. Often, cells one off the diagonal are weighted 1, those two off 2, etc.</p>
<p>Quadratic weighted kappa (QWK) typically varies from 0 (random agreement between raters) to 1 (complete agreement between raters). In the event that there is less agreement between the raters than expected by chance, the metric may go below 0. The quadratic weighted kappa is calculated between the scores which are expected/known and the predicted scores.</p>
<p>QWK can be defined in terms of the relationship of the elements of a confusion matrix.</p>
<figure class="figure">
<p><img src="files_for_readme/qwk.png" alt="where TP= True Positives, FP=False Positives, TN= True Negatives and FN= False Negatives" data-fig-align="left" class="figure-img"></p>
<figcaption aria-hidden="true" class="figure-caption">
<p>where TP= True Positives, FP=False Positives, TN= True Negatives and FN= False Negatives</p>
</figcaption>
</figure>
<p>For more information see the following <a href="https://www.kaggle.com/code/aroraaman/quadratic-kappa-metric-explained-in-5-simple-steps/notebook">Kaggle explanation</a>.</p>
</section>
<section id="standardized-mean-difference" class="level3">
<h3 class="anchored" data-anchor-id="standardized-mean-difference">Standardized mean difference</h3>
<p>This statistic will be used to evaluate responses for potential bias in scoring by different student populations. The standarized mean difference is the difference in given by.</p>
<p><span class="math display">\[\frac{\mu_A - \mu_B}{\frac{(n_A -1) s_A^2 + (n_B -1)s_B^2}{n_A + n_B - 2}}\]</span></p>
<p>where <span class="math inline">\(\mu_X\)</span> is the mean of group <span class="math inline">\(X\)</span>, <span class="math inline">\(n_X\)</span> is the n-size for group <span class="math inline">\(X\)</span>, and <span class="math inline">\(s_A\)</span> is the sample standard deviation for group <span class="math inline">\(X\)</span>.</p>
</section>
</section>
<section id="response-distributions-by-item" class="level2">
<h2 class="anchored" data-anchor-id="response-distributions-by-item">Response Distributions by Item</h2>
<p>Histograms showings the distribution of variable values for each item in the training data follow. <br></p>
<section id="response-percentages" class="level3">
<h3 class="anchored" data-anchor-id="response-percentages">Response Percentages</h3>
<p><img src="files_for_readme/doublescored_pct_VH134067_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH139380_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH266015_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH266510_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH269384_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH271613_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH302907_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH304954_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH507804_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_pct_VH525628_plots_90_10_byValue2023-02-22.png" style="width:90.0%"></p>
</section>
<section id="response-counts" class="level3">
<h3 class="anchored" data-anchor-id="response-counts">Response Counts</h3>
<p><img src="files_for_readme/doublescored_VH134067_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH139380_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH266015_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH266510_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH269384_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH271613_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH302907_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH304954_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH507804_plots_90_10_byValue2023-02-22.png" style="width:90.0%"> <img src="files_for_readme/doublescored_VH525628_plots_90_10_byValue2023-02-22.png" style="width:90.0%"></p>
<p><a id="references" href=""></a> # References</p>
<div>

</div>
</section>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Constructed response question types ask students to enter either a longer written response or a series of shorter inter-related responses Depending on the subject area assessed, students may be asked to provide an explanation, an interpretation, a justification, or to describe or show the steps for the solution of a problem. These questions require longer written responses than short constructed responses.”<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>